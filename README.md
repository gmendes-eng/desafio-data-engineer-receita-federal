### Desafio de Engenharia de Dados - Pipeline da Receita Federal
Este reposit√≥rio cont√©m a solu√ß√£o para o desafio de engenharia de dados, que consiste em construir um pipeline para ingest√£o, processamento e armazenamento de dados p√∫blicos de CNPJ da Receita Federal.

### üìù Descri√ß√£o do Projeto
O pipeline foi constru√≠do utilizando a arquitetura Medallion **(Bronze, Silver, Gold)** para garantir a qualidade e a rastreabilidade dos dados. O processo completo √© orquestrado com Docker e Docker Compose, permitindo que todo o ambiente seja executado com um √∫nico comando.

**Camada Bronze:** Ingest√£o dos dados brutos (.zip) da fonte oficial.

**Camada Silver:** Limpeza, padroniza√ß√£o de schemas, convers√£o de tipos e armazenamento em formato Parquet.

**Camada Gold:** Aplica√ß√£o das regras de neg√≥cio solicitadas no desafio (c√°lculo de quantidade de s√≥cios, flags, etc.), com o resultado salvo em Parquet e carregado em um banco de dados.

### üèõÔ∏è Desenho da Arquitetura da Solu√ß√£o
O diagrama abaixo ilustra o fluxo completo, desde a fonte dos dados at√© o armazenamento final:

```mermaid
graph TD;
    subgraph "Fonte de Dados Externa"
        A["<b>Portal de Dados Abertos</b><br>Receita Federal<br>(Arquivos .zip)"]
    end

    subgraph "Ambiente Dockerizado (docker-compose)"
        subgraph "Container da Aplica√ß√£o (app_stone)"
            B("<b>Script de Ingest√£o</b><br>ingestion.py")
            
            subgraph "Camadas (Sistema de Arquivos do Container)"
                C("<b>Camada Bronze</b><br>data/bronze<br>CSVs brutos")
                D("<b>Camada Silver</b><br>data/silver<br>Parquet limpo")
                E("<b>Camada Gold</b><br>data/gold<br>Parquet agregado")
            end

            F("<b>Processamento com PySpark</b><br>transformations.py")
        end

        subgraph "Container do Banco de Dados (db_stone)"
            G["<b>PostgreSQL</b><br>Tabela 'resultado_final_desafio'"]
        end
    end

    subgraph "Consumidores Finais"
        H["<b>Ferramenta de BI / API</b><br>Acessando o PostgreSQL"]
    end

    %% Fluxo do Pipeline
    A -->|"1. Download e Descompacta√ß√£o"| B;
    B -->|"2. Salva bruto"| C;
    C -->|"3. L√™ bruto"| F;
    F -->|"4. Salva limpo"| D;
    D -->|"5. L√™ limpo"| F;
    F -->|"6. Salva agregado"| E;
    E -->|"7. L√™ agregado para carregar"| F;
    F -->|"8. Carrega no Banco"| G;
    G -->|"9. Consulta"| H;
```

### üõ†Ô∏è Tecnologias Utilizadas
- **Linguagem:** Python 3.12

- **Processamento de Dados:** Apache Spark (via PySpark)

- **Banco de Dados:** PostgreSQL

- **Orquestra√ß√£o e Ambiente:** Docker e Docker Compose

### üöÄ Como Executar o Projeto
**Pr√©-requisitos:**
- Git

- Docker e Docker Compose instalados e em execu√ß√£o.

**Passo a Passo:**
1. **Clone o reposit√≥rio:**

`git clone https://github.com/gmendes-eng/desafio-data-engineer-receita-federal.git`

2. **Navegue at√© a pasta do projeto:**

`cd desafio-data-engineer-receita-federal`

3. **Execute o pipeline com Docker Compose:**

`docker-compose up --build`

Este √∫nico comando ir√° construir a imagem da aplica√ß√£o, baixar todas as depend√™ncias, iniciar o container do banco de dados e executar o pipeline completo de ponta a ponta. O processo pode levar v√°rios minutos na primeira execu√ß√£o.

### ‚úÖ Como Verificar o Resultado
Ap√≥s a execu√ß√£o bem-sucedida, voc√™ pode verificar o resultado de duas formas:

1. **Arquivos F√≠sicos:**
As sa√≠das de cada camada s√£o salvas na pasta `data/`, permitindo auditoria e valida√ß√£o:

- `data/bronze`: Cont√©m os dados brutos descompactados.

- `data/silver`: Cont√©m os dados limpos em formato Parquet.

- `data/gold`: Cont√©m o resultado final em formato Parquet.

2. **Banco de Dados PostgreSQL:**
O resultado final √© carregado na tabela resultado_final_desafio. Voc√™ pode usar um cliente de banco de dados (como DBeaver ou DataGrip) para se conectar com as seguintes credenciais:

- **Host:** `localhost`

- **Porta:** `5432`

- **Banco de Dados:** `stone_db`

- **Usu√°rio:** `user`

- **Senha:** `password`

### üìÑ Documenta√ß√£o de Refer√™ncia
O layout e o schema dos arquivos brutos da Receita Federal foram baseados na documenta√ß√£o oficial disponibilizada pelo governo.

- **Layout dos Arquivos:** [Metadados dos Dados Abertos de CNPJ](https://www.gov.br/receitafederal/dados/cnpj-metadados.pdf)